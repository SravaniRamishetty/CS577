{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-analyze Improved Results with Fixed Evaluator\n",
    "\n",
    "This notebook re-analyzes the existing improved experiment results using the **FIXED** evaluator that now handles incomplete `<think>` tags.\n",
    "\n",
    "**Why**: The original analysis had a bug where truncated generations (missing `</think>`) showed `think_tokens=0`.\n",
    "\n",
    "**What we do**: Load saved outputs from `results_improved/results.json` and re-extract quality metrics using the fixed code.\n",
    "\n",
    "**Expected**: Will reveal true reasoning patterns that were masked by the evaluation bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sramishe/.venv llm-env/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sramishe/.venv llm-env/lib64/python3.9/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ Using FIXED evaluator that handles incomplete tags\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../pipeline')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import the FIXED evaluator\n",
    "from evaluator import ReasoningEvaluator\n",
    "\n",
    "# For tokenization\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/scratch/gilbreth/sramishe'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/gilbreth/sramishe/transformers'\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(\"✓ Using FIXED evaluator that handles incomplete tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded results from: /scratch/gilbreth/sramishe/results_QwQ_R1/results_improved/results.json\n",
      "\n",
      "Configuration:\n",
      "  rl_model_name: Qwen/QwQ-32B\n",
      "  distilled_model_name: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
      "  dataset_name: HuggingFaceH4/MATH-500\n",
      "  num_samples: 20\n",
      "  strength_range: [-2.0, 2.0]\n",
      "  num_strengths: 9\n",
      "  num_test_prompts: 5\n",
      "  output_dir: /scratch/gilbreth/sramishe/results_QwQ_R1/results_improved\n",
      "  max_new_tokens: 1024\n",
      "  layers_step: 4\n",
      "\n",
      "Data keys: ['config', 'model_info', 'directions_stats', 'baselines', 'critical_layers', 'critical_layers_think', 'layer_sensitivity', 'layer_sensitivity_think', 'quality_variance', 'top_quality_layers', 'intervention_results']\n",
      "Total intervention results: 144\n",
      "Baseline generations: 5\n"
     ]
    }
   ],
   "source": [
    "# Load results\n",
    "results_path = Path('/scratch/gilbreth/sramishe/results_QwQ_R1/results_improved/results.json')\n",
    "\n",
    "with open(results_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded results from: {results_path}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in data['config'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nData keys: {list(data.keys())}\")\n",
    "print(f\"Total intervention results: {len(data['intervention_results'])}\")\n",
    "print(f\"Baseline generations: {len(data['baselines'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fixed Evaluator and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "✓ Fixed evaluator initialized\n",
      "✓ Tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "# Initialize fixed evaluator\n",
    "evaluator = ReasoningEvaluator()\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(data['config']['rl_model_name'])\n",
    "\n",
    "print(\"✓ Fixed evaluator initialized\")\n",
    "print(\"✓ Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fix on Baseline Generation\n",
    "\n",
    "Let's verify the fix works on the baseline generation that previously showed `think_tokens=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE GENERATION (Original metrics - BUGGY)\n",
      "================================================================================\n",
      "Total tokens (saved): 1077\n",
      "Think tokens (saved): 0\n",
      "Non-think tokens (saved): 1077\n",
      "Reasoning steps (saved): 0\n",
      "Has think tags (saved): False\n",
      "\n",
      "================================================================================\n",
      "BASELINE GENERATION (Re-analyzed with FIXED evaluator)\n",
      "================================================================================\n",
      "Has <think>: True\n",
      "Has </think>: False\n",
      "⚠️  TRUNCATED: Has opening tag but missing closing tag\n",
      "\n",
      "Total tokens (fixed): 1077\n",
      "Think tokens (fixed): 1024\n",
      "Non-think tokens (fixed): 52\n",
      "Reasoning steps (fixed): 15\n",
      "Has think tags (fixed): True\n",
      "Backtracking (fixed): 2\n",
      "Hesitation (fixed): 1\n",
      "Verbosity (fixed): 680\n",
      "\n",
      "================================================================================\n",
      "COMPARISON\n",
      "================================================================================\n",
      "Think tokens: 0 → 1024 (+1024)\n",
      "Reasoning steps: 0 → 15 (+15)\n",
      "\n",
      "✅ FIX CONFIRMED: Now detecting think content that was previously missed!\n"
     ]
    }
   ],
   "source": [
    "# Get first baseline\n",
    "baseline = data['baselines'][0]\n",
    "\n",
    "print(\"BASELINE GENERATION (Original metrics - BUGGY)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total tokens (saved): {baseline['tokens']['total_tokens']}\")\n",
    "print(f\"Think tokens (saved): {baseline['tokens']['think_tokens']}\")\n",
    "print(f\"Non-think tokens (saved): {baseline['tokens']['non_think_tokens']}\")\n",
    "print(f\"Reasoning steps (saved): {baseline['quality']['reasoning_steps']}\")\n",
    "print(f\"Has think tags (saved): {baseline['quality']['has_think_tags']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE GENERATION (Re-analyzed with FIXED evaluator)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Re-analyze with FIXED evaluator\n",
    "text = baseline['text']\n",
    "\n",
    "# Check for incomplete tags\n",
    "has_opening = '<think>' in text\n",
    "has_closing = '</think>' in text\n",
    "print(f\"Has <think>: {has_opening}\")\n",
    "print(f\"Has </think>: {has_closing}\")\n",
    "if has_opening and not has_closing:\n",
    "    print(\"⚠️  TRUNCATED: Has opening tag but missing closing tag\")\n",
    "\n",
    "# Re-extract with fixed code\n",
    "tokens_fixed = evaluator.count_tokens(text, tokenizer, split_by_tags=True)\n",
    "quality_fixed = evaluator.analyze_reasoning_quality(text)\n",
    "\n",
    "print(f\"\\nTotal tokens (fixed): {tokens_fixed['total_tokens']}\")\n",
    "print(f\"Think tokens (fixed): {tokens_fixed['think_tokens']}\")\n",
    "print(f\"Non-think tokens (fixed): {tokens_fixed['non_think_tokens']}\")\n",
    "print(f\"Reasoning steps (fixed): {quality_fixed['reasoning_steps']}\")\n",
    "print(f\"Has think tags (fixed): {quality_fixed['has_think_tags']}\")\n",
    "print(f\"Backtracking (fixed): {quality_fixed['backtracking_count']}\")\n",
    "print(f\"Hesitation (fixed): {quality_fixed['hesitation_count']}\")\n",
    "print(f\"Verbosity (fixed): {quality_fixed['verbosity']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Think tokens: {baseline['tokens']['think_tokens']} → {tokens_fixed['think_tokens']} ({tokens_fixed['think_tokens'] - baseline['tokens']['think_tokens']:+d})\")\n",
    "print(f\"Reasoning steps: {baseline['quality']['reasoning_steps']} → {quality_fixed['reasoning_steps']} ({quality_fixed['reasoning_steps'] - baseline['quality']['reasoning_steps']:+d})\")\n",
    "\n",
    "if tokens_fixed['think_tokens'] > 0 and baseline['tokens']['think_tokens'] == 0:\n",
    "    print(\"\\n✅ FIX CONFIRMED: Now detecting think content that was previously missed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No change detected - investigating further\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-analyze ALL Intervention Results\n",
    "\n",
    "Now re-analyze all 144 intervention results with the fixed evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-analyzing all intervention results with FIXED evaluator...\n",
      "Total results to process: 144\n",
      "  Processed 20/144...\n",
      "  Processed 40/144...\n",
      "  Processed 60/144...\n",
      "  Processed 80/144...\n",
      "  Processed 100/144...\n",
      "  Processed 120/144...\n",
      "  Processed 140/144...\n",
      "\n",
      "✓ Re-analysis complete!\n",
      "Changes detected: 122/144 results\n",
      "Percentage changed: 84.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Re-analyzing all intervention results with FIXED evaluator...\")\n",
    "print(f\"Total results to process: {len(data['intervention_results'])}\")\n",
    "\n",
    "# Store fixed results\n",
    "fixed_results = []\n",
    "changes_detected = 0\n",
    "\n",
    "for i, result in enumerate(data['intervention_results']):\n",
    "    # Get saved (buggy) metrics\n",
    "    old_tokens = result.get('tokens', {})\n",
    "    old_quality = result.get('quality', {})\n",
    "    old_think_tokens = old_tokens.get('think_tokens', 0)\n",
    "    \n",
    "    # Re-analyze with fixed evaluator\n",
    "    text = result['output']\n",
    "    new_tokens = evaluator.count_tokens(text, tokenizer, split_by_tags=True)\n",
    "    new_quality = evaluator.analyze_reasoning_quality(text)\n",
    "    \n",
    "    # Track if anything changed\n",
    "    if new_tokens['think_tokens'] != old_think_tokens:\n",
    "        changes_detected += 1\n",
    "    \n",
    "    # Store fixed result\n",
    "    fixed_result = {\n",
    "        'layer': result['layer'],\n",
    "        'strength': result['strength'],\n",
    "        'output': text,\n",
    "        'token_count': result['token_count'],\n",
    "        'tokens_old': old_tokens,\n",
    "        'quality_old': old_quality,\n",
    "        'tokens': new_tokens,\n",
    "        'quality': new_quality,\n",
    "        'changed': new_tokens['think_tokens'] != old_think_tokens\n",
    "    }\n",
    "    fixed_results.append(fixed_result)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Processed {i+1}/{len(data['intervention_results'])}...\")\n",
    "\n",
    "print(f\"\\n✓ Re-analysis complete!\")\n",
    "print(f\"Changes detected: {changes_detected}/{len(fixed_results)} results\")\n",
    "print(f\"Percentage changed: {100*changes_detected/len(fixed_results):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Changes by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHANGES BY LAYER\n",
      "================================================================================\n",
      "\n",
      "Layer 0: 6/9 results changed\n",
      "  Strengths affected: [-1.0, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -1.0: think_tokens    0 → 1024 (+1024)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 4: 9/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 8: 8/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 12: 8/9 results changed\n",
      "  Strengths affected: [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 16: 7/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 20: 6/9 results changed\n",
      "  Strengths affected: [-2.0, -1.0, -0.5, 0.0, 0.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 24: 7/9 results changed\n",
      "  Strengths affected: [-1.5, -1.0, -0.5, 0.0, 1.0, 1.5, 2.0]\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 28: 7/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, 0.0, 0.5, 1.0, 1.5]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 32: 6/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -0.5, 0.0, 0.5, 1.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 36: 9/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 40: 8/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 44: 7/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1024 (+1024)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 48: 9/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 52: 7/9 results changed\n",
      "  Strengths affected: [-2.0, -1.0, -0.5, 0.0, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 56: 9/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n",
      "\n",
      "Layer 60: 9/9 results changed\n",
      "  Strengths affected: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]\n",
      "    Strength  -2.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength  -0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   0.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.0: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   1.5: think_tokens    0 → 1025 (+1025)\n",
      "    Strength   2.0: think_tokens    0 → 1025 (+1025)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CHANGES BY LAYER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "layers = sorted(set(r['layer'] for r in fixed_results))\n",
    "\n",
    "for layer in layers:\n",
    "    layer_results = [r for r in fixed_results if r['layer'] == layer]\n",
    "    changed = sum(1 for r in layer_results if r['changed'])\n",
    "    \n",
    "    if changed > 0:\n",
    "        print(f\"\\nLayer {layer}: {changed}/{len(layer_results)} results changed\")\n",
    "        \n",
    "        # Show which strengths changed\n",
    "        changed_strengths = [r['strength'] for r in layer_results if r['changed']]\n",
    "        print(f\"  Strengths affected: {sorted(set(changed_strengths))}\")\n",
    "        \n",
    "        # Show old vs new for changed results\n",
    "        for r in layer_results:\n",
    "            if r['changed']:\n",
    "                old = r['tokens_old'].get('think_tokens', 0)\n",
    "                new = r['tokens']['think_tokens']\n",
    "                print(f\"    Strength {r['strength']:>5.1f}: think_tokens {old:>4d} → {new:>4d} ({new-old:+5d})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis: Layer 0\n",
    "\n",
    "Layer 0 showed the most promise for improvement (negative strengths induced reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LAYER 0 - DETAILED ANALYSIS (Before vs After Fix)\n",
      "================================================================================\n",
      "\n",
      "Strength   Old Think    New Think    Delta    Old Steps    New Steps    Status\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      -2.0  884          884               +0  13           13           ✓ Reasoning\n",
      "      -1.5  787          787               +0  12           12           ✓ Reasoning\n",
      "*     -1.0  0            1024           +1024  0            17           ✓ Reasoning\n",
      "      -0.5  889          889               +0  15           15           ✓ Reasoning\n",
      "*      0.0  0            1025           +1025  0            16           ✓ Reasoning\n",
      "*      0.5  0            1025           +1025  0            16           ✓ Reasoning\n",
      "*      1.0  0            1025           +1025  0            18           ✓ Reasoning\n",
      "*      1.5  0            1025           +1025  0            23           ✓ Reasoning\n",
      "*      2.0  0            1025           +1025  0            16           ✓ Reasoning\n",
      "\n",
      "* = Changed with fix\n",
      "\n",
      "================================================================================\n",
      "KEY FINDING FOR LAYER 0:\n",
      "================================================================================\n",
      "Baseline (strength=0.0):\n",
      "  Old think_tokens: 0\n",
      "  New think_tokens: 1025\n",
      "\n",
      "✅ BASELINE NOW SHOWS REASONING!\n",
      "   - The 'only negative strengths work' pattern was due to evaluation bug\n",
      "   - Baseline was truncated, missing </think> tag\n",
      "   - Need to re-evaluate whether negative strengths are truly better\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LAYER 0 - DETAILED ANALYSIS (Before vs After Fix)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "layer0_results = sorted([r for r in fixed_results if r['layer'] == 0], key=lambda x: x['strength'])\n",
    "\n",
    "print(f\"\\n{'Strength':<10} {'Old Think':<12} {'New Think':<12} {'Delta':<8} {'Old Steps':<12} {'New Steps':<12} {'Status'}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for r in layer0_results:\n",
    "    old_think = r['tokens_old'].get('think_tokens', 0)\n",
    "    new_think = r['tokens']['think_tokens']\n",
    "    delta = new_think - old_think\n",
    "    \n",
    "    old_steps = r['quality_old'].get('reasoning_steps', 0)\n",
    "    new_steps = r['quality']['reasoning_steps']\n",
    "    \n",
    "    if new_think > 0:\n",
    "        status = \"✓ Reasoning\" if delta >= 0 else \"✓ Reasoning (fixed)\"\n",
    "    else:\n",
    "        status = \"⚠️  Suppressed\"\n",
    "    \n",
    "    changed_marker = \"*\" if r['changed'] else \" \"\n",
    "    \n",
    "    print(f\"{changed_marker}{r['strength']:>9.1f}  {old_think:<12} {new_think:<12} {delta:>+7d}  {old_steps:<12} {new_steps:<12} {status}\")\n",
    "\n",
    "print(\"\\n* = Changed with fix\")\n",
    "\n",
    "# Key finding\n",
    "baseline = [r for r in layer0_results if r['strength'] == 0.0][0]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"KEY FINDING FOR LAYER 0:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Baseline (strength=0.0):\")\n",
    "print(f\"  Old think_tokens: {baseline['tokens_old'].get('think_tokens', 0)}\")\n",
    "print(f\"  New think_tokens: {baseline['tokens']['think_tokens']}\")\n",
    "\n",
    "if baseline['tokens']['think_tokens'] > 0 and baseline['tokens_old'].get('think_tokens', 0) == 0:\n",
    "    print(f\"\\n✅ BASELINE NOW SHOWS REASONING!\")\n",
    "    print(f\"   - The 'only negative strengths work' pattern was due to evaluation bug\")\n",
    "    print(f\"   - Baseline was truncated, missing </think> tag\")\n",
    "    print(f\"   - Need to re-evaluate whether negative strengths are truly better\")\n",
    "elif baseline['tokens']['think_tokens'] == 0:\n",
    "    print(f\"\\n⚠️  Baseline still shows no reasoning\")\n",
    "    print(f\"   - Pattern holds: negative strengths DO induce reasoning at layer 0\")\n",
    "    print(f\"   - This supports the inverse direction hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis: Layer 16\n",
    "\n",
    "Layer 16 was most sensitive (32-token range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LAYER 16 - DETAILED ANALYSIS (Before vs After Fix)\n",
      "================================================================================\n",
      "\n",
      "Strength   Old Think    New Think    Delta    Old Steps    New Steps    Status\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*     -2.0  0            1025           +1025  0            28           ✓ Reasoning\n",
      "*     -1.5  0            1025           +1025  0            21           ✓ Reasoning\n",
      "*     -1.0  0            1025           +1025  0            22           ✓ Reasoning\n",
      "      -0.5  802          802               +0  12           12           ✓ Reasoning\n",
      "       0.0  973          973               +0  18           18           ✓ Reasoning\n",
      "*      0.5  0            1025           +1025  0            18           ✓ Reasoning\n",
      "*      1.0  0            1025           +1025  0            24           ✓ Reasoning\n",
      "*      1.5  0            1025           +1025  0            26           ✓ Reasoning\n",
      "*      2.0  0            1025           +1025  0            18           ✓ Reasoning\n",
      "\n",
      "* = Changed with fix\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LAYER 16 - DETAILED ANALYSIS (Before vs After Fix)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "layer16_results = sorted([r for r in fixed_results if r['layer'] == 16], key=lambda x: x['strength'])\n",
    "\n",
    "print(f\"\\n{'Strength':<10} {'Old Think':<12} {'New Think':<12} {'Delta':<8} {'Old Steps':<12} {'New Steps':<12} {'Status'}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for r in layer16_results:\n",
    "    old_think = r['tokens_old'].get('think_tokens', 0)\n",
    "    new_think = r['tokens']['think_tokens']\n",
    "    delta = new_think - old_think\n",
    "    \n",
    "    old_steps = r['quality_old'].get('reasoning_steps', 0)\n",
    "    new_steps = r['quality']['reasoning_steps']\n",
    "    \n",
    "    if new_think > 0:\n",
    "        status = \"✓ Reasoning\"\n",
    "    else:\n",
    "        status = \"⚠️  Suppressed\"\n",
    "    \n",
    "    changed_marker = \"*\" if r['changed'] else \" \"\n",
    "    \n",
    "    print(f\"{changed_marker}{r['strength']:>9.1f}  {old_think:<12} {new_think:<12} {delta:>+7d}  {old_steps:<12} {new_steps:<12} {status}\")\n",
    "\n",
    "print(\"\\n* = Changed with fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis: Layer 20\n",
    "\n",
    "Layer 20 showed highest quality variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LAYER 20 - DETAILED ANALYSIS (Before vs After Fix)\n",
      "================================================================================\n",
      "\n",
      "Strength   Old Think    New Think    Delta    Old Steps    New Steps    Status\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*     -2.0  0            1025           +1025  0            19           ✓ Reasoning\n",
      "      -1.5  992          992               +0  19           19           ✓ Reasoning\n",
      "*     -1.0  0            1025           +1025  0            11           ✓ Reasoning\n",
      "*     -0.5  0            1025           +1025  0            24           ✓ Reasoning\n",
      "*      0.0  0            1025           +1025  0            17           ✓ Reasoning\n",
      "*      0.5  0            1025           +1025  0            21           ✓ Reasoning\n",
      "       1.0  973          973               +0  16           16           ✓ Reasoning\n",
      "       1.5  918          918               +0  20           20           ✓ Reasoning\n",
      "*      2.0  0            1025           +1025  0            23           ✓ Reasoning\n",
      "\n",
      "* = Changed with fix\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LAYER 20 - DETAILED ANALYSIS (Before vs After Fix)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "layer20_results = sorted([r for r in fixed_results if r['layer'] == 20], key=lambda x: x['strength'])\n",
    "\n",
    "print(f\"\\n{'Strength':<10} {'Old Think':<12} {'New Think':<12} {'Delta':<8} {'Old Steps':<12} {'New Steps':<12} {'Status'}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for r in layer20_results:\n",
    "    old_think = r['tokens_old'].get('think_tokens', 0)\n",
    "    new_think = r['tokens']['think_tokens']\n",
    "    delta = new_think - old_think\n",
    "    \n",
    "    old_steps = r['quality_old'].get('reasoning_steps', 0)\n",
    "    new_steps = r['quality']['reasoning_steps']\n",
    "    \n",
    "    if new_think > 0:\n",
    "        status = \"✓ Reasoning\"\n",
    "    else:\n",
    "        status = \"⚠️  Suppressed\"\n",
    "    \n",
    "    changed_marker = \"*\" if r['changed'] else \" \"\n",
    "    \n",
    "    print(f\"{changed_marker}{r['strength']:>9.1f}  {old_think:<12} {new_think:<12} {delta:>+7d}  {old_steps:<12} {new_steps:<12} {status}\")\n",
    "\n",
    "print(\"\\n* = Changed with fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY: OLD VS NEW METRICS\n",
      "================================================================================\n",
      "\n",
      "Total results: 144\n",
      "\n",
      "Results with reasoning (think_tokens > 0):\n",
      "  Old (buggy): 22/144 (15.3%)\n",
      "  New (fixed): 144/144 (100.0%)\n",
      "  Change: +122 results now show reasoning\n",
      "\n",
      "Think tokens statistics:\n",
      "  Old mean: 141.6\n",
      "  New mean: 1010.0\n",
      "  Old std: 334.6\n",
      "  New std: 44.6\n",
      "\n",
      "Breakdown:\n",
      "  Unchanged: 22/144 (15.3%)\n",
      "  Increased: 122/144 (84.7%)\n",
      "  Decreased: 0/144 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY: OLD VS NEW METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate statistics\n",
    "old_think_tokens = [r['tokens_old'].get('think_tokens', 0) for r in fixed_results]\n",
    "new_think_tokens = [r['tokens']['think_tokens'] for r in fixed_results]\n",
    "\n",
    "old_has_reasoning = sum(1 for t in old_think_tokens if t > 0)\n",
    "new_has_reasoning = sum(1 for t in new_think_tokens if t > 0)\n",
    "\n",
    "print(f\"\\nTotal results: {len(fixed_results)}\")\n",
    "print(f\"\\nResults with reasoning (think_tokens > 0):\")\n",
    "print(f\"  Old (buggy): {old_has_reasoning}/{len(fixed_results)} ({100*old_has_reasoning/len(fixed_results):.1f}%)\")\n",
    "print(f\"  New (fixed): {new_has_reasoning}/{len(fixed_results)} ({100*new_has_reasoning/len(fixed_results):.1f}%)\")\n",
    "print(f\"  Change: {new_has_reasoning - old_has_reasoning:+d} results now show reasoning\")\n",
    "\n",
    "print(f\"\\nThink tokens statistics:\")\n",
    "print(f\"  Old mean: {np.mean(old_think_tokens):.1f}\")\n",
    "print(f\"  New mean: {np.mean(new_think_tokens):.1f}\")\n",
    "print(f\"  Old std: {np.std(old_think_tokens):.1f}\")\n",
    "print(f\"  New std: {np.std(new_think_tokens):.1f}\")\n",
    "\n",
    "# Breakdown by result\n",
    "unchanged = sum(1 for r in fixed_results if not r['changed'])\n",
    "increased = sum(1 for r in fixed_results if r['changed'] and r['tokens']['think_tokens'] > r['tokens_old'].get('think_tokens', 0))\n",
    "decreased = sum(1 for r in fixed_results if r['changed'] and r['tokens']['think_tokens'] < r['tokens_old'].get('think_tokens', 0))\n",
    "\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  Unchanged: {unchanged}/{len(fixed_results)} ({100*unchanged/len(fixed_results):.1f}%)\")\n",
    "print(f\"  Increased: {increased}/{len(fixed_results)} ({100*increased/len(fixed_results):.1f}%)\")\n",
    "print(f\"  Decreased: {decreased}/{len(fixed_results)} ({100*decreased/len(fixed_results):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Before vs After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame created with 144 rows\n",
      "\n",
      "Sample:\n",
      "   layer  strength  think_tokens_old  think_tokens_new  reasoning_steps_old  reasoning_steps_new  changed\n",
      "0      0      -2.0               884               884                   13                   13    False\n",
      "1      0      -1.5               787               787                   12                   12    False\n",
      "2      0      -1.0                 0              1024                    0                   17     True\n",
      "3      0      -0.5               889               889                   15                   15    False\n",
      "4      0       0.0                 0              1025                    0                   16     True\n",
      "5      0       0.5                 0              1025                    0                   16     True\n",
      "6      0       1.0                 0              1025                    0                   18     True\n",
      "7      0       1.5                 0              1025                    0                   23     True\n",
      "8      0       2.0                 0              1025                    0                   16     True\n",
      "9      4      -2.0                 0              1025                    0                   17     True\n",
      "\n",
      "✓ Saved to /scratch/gilbreth/sramishe/results_QwQ_R1/results_improved/fixed_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for analysis\n",
    "df = pd.DataFrame([{\n",
    "    'layer': r['layer'],\n",
    "    'strength': r['strength'],\n",
    "    'think_tokens_old': r['tokens_old'].get('think_tokens', 0),\n",
    "    'think_tokens_new': r['tokens']['think_tokens'],\n",
    "    'reasoning_steps_old': r['quality_old'].get('reasoning_steps', 0),\n",
    "    'reasoning_steps_new': r['quality']['reasoning_steps'],\n",
    "    'changed': r['changed']\n",
    "} for r in fixed_results])\n",
    "\n",
    "print(\"\\nDataFrame created with\", len(df), \"rows\")\n",
    "print(\"\\nSample:\")\n",
    "print(df.head(10).to_string())\n",
    "\n",
    "# Save fixed results\n",
    "output_path = Path('/scratch/gilbreth/sramishe/results_QwQ_R1/results_improved')\n",
    "df.to_csv(output_path / 'fixed_analysis.csv', index=False)\n",
    "print(f\"\\n✓ Saved to {output_path / 'fixed_analysis.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY FINDINGS FROM RE-ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. SCOPE OF BUG\n",
      "   - 122/144 results affected (84.7%)\n",
      "   - These results previously showed think_tokens=0 due to truncation\n",
      "   - Now correctly detected with fixed evaluator\n",
      "\n",
      "2. LAYERS MOST AFFECTED BY BUG\n",
      "   Layer 4: 9/9 results changed\n",
      "   Layer 36: 9/9 results changed\n",
      "   Layer 48: 9/9 results changed\n",
      "   Layer 56: 9/9 results changed\n",
      "   Layer 60: 9/9 results changed\n",
      "   Layer 8: 8/9 results changed\n",
      "   Layer 12: 8/9 results changed\n",
      "   Layer 40: 8/9 results changed\n",
      "   Layer 16: 7/9 results changed\n",
      "   Layer 24: 7/9 results changed\n",
      "   Layer 28: 7/9 results changed\n",
      "   Layer 44: 7/9 results changed\n",
      "   Layer 52: 7/9 results changed\n",
      "   Layer 0: 6/9 results changed\n",
      "   Layer 20: 6/9 results changed\n",
      "   Layer 32: 6/9 results changed\n",
      "\n",
      "3. LAYER 0 INVERSE DIRECTION HYPOTHESIS\n",
      "   Baseline (strength=0.0) think_tokens:\n",
      "   - Old: 0\n",
      "   - New: 1025\n",
      "   ⚠️  HYPOTHESIS INVALIDATED\n",
      "   - Baseline WAS truncated, not truly suppressed\n",
      "   - Need to compare quality, not just presence of reasoning\n",
      "\n",
      "4. OVERALL IMPACT\n",
      "   Results showing reasoning:\n",
      "   - Old: 22/144 (15.3%)\n",
      "   - New: 144/144 (100.0%)\n",
      "   - Net change: +122 (+84.7%)\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION\n",
      "================================================================================\n",
      "\n",
      "The evaluation bug fix successfully detects think content in truncated\n",
      "generations. This provides more accurate quality metrics for analysis.\n",
      "\n",
      "Next steps:\n",
      "1. Review Layer 0 baseline - does it truly suppress reasoning?\n",
      "2. Compare QUALITY not just PRESENCE of reasoning\n",
      "3. Test inverse direction on MATH-500 with correctness grading\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS FROM RE-ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Finding 1: How many results were affected?\n",
    "print(f\"\\n1. SCOPE OF BUG\")\n",
    "print(f\"   - {changes_detected}/{len(fixed_results)} results affected ({100*changes_detected/len(fixed_results):.1f}%)\")\n",
    "print(f\"   - These results previously showed think_tokens=0 due to truncation\")\n",
    "print(f\"   - Now correctly detected with fixed evaluator\")\n",
    "\n",
    "# Finding 2: Which layers were most affected?\n",
    "layers_affected = defaultdict(int)\n",
    "for r in fixed_results:\n",
    "    if r['changed']:\n",
    "        layers_affected[r['layer']] += 1\n",
    "\n",
    "print(f\"\\n2. LAYERS MOST AFFECTED BY BUG\")\n",
    "for layer, count in sorted(layers_affected.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   Layer {layer}: {count}/9 results changed\")\n",
    "\n",
    "# Finding 3: Impact on Layer 0 hypothesis\n",
    "layer0_baseline = [r for r in fixed_results if r['layer'] == 0 and r['strength'] == 0.0][0]\n",
    "print(f\"\\n3. LAYER 0 INVERSE DIRECTION HYPOTHESIS\")\n",
    "print(f\"   Baseline (strength=0.0) think_tokens:\")\n",
    "print(f\"   - Old: {layer0_baseline['tokens_old'].get('think_tokens', 0)}\")\n",
    "print(f\"   - New: {layer0_baseline['tokens']['think_tokens']}\")\n",
    "\n",
    "if layer0_baseline['changed']:\n",
    "    print(f\"   ⚠️  HYPOTHESIS INVALIDATED\")\n",
    "    print(f\"   - Baseline WAS truncated, not truly suppressed\")\n",
    "    print(f\"   - Need to compare quality, not just presence of reasoning\")\n",
    "else:\n",
    "    print(f\"   ✓ HYPOTHESIS STILL VALID\")\n",
    "    print(f\"   - Baseline truly shows no reasoning\")\n",
    "    print(f\"   - Negative strengths genuinely induce reasoning\")\n",
    "\n",
    "# Finding 4: Overall impact\n",
    "print(f\"\\n4. OVERALL IMPACT\")\n",
    "print(f\"   Results showing reasoning:\")\n",
    "print(f\"   - Old: {old_has_reasoning}/{len(fixed_results)} ({100*old_has_reasoning/len(fixed_results):.1f}%)\")\n",
    "print(f\"   - New: {new_has_reasoning}/{len(fixed_results)} ({100*new_has_reasoning/len(fixed_results):.1f}%)\")\n",
    "print(f\"   - Net change: {new_has_reasoning - old_has_reasoning:+d} ({100*(new_has_reasoning - old_has_reasoning)/len(fixed_results):+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThe evaluation bug fix successfully detects think content in truncated\")\n",
    "print(\"generations. This provides more accurate quality metrics for analysis.\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review Layer 0 baseline - does it truly suppress reasoning?\")\n",
    "print(\"2. Compare QUALITY not just PRESENCE of reasoning\")\n",
    "print(\"3. Test inverse direction on MATH-500 with correctness grading\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Fixed Results\n",
    "\n",
    "Save the re-analyzed results for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fixed results saved to /scratch/gilbreth/sramishe/results_QwQ_R1/results_improved/results_fixed.json\n",
      "✓ CSV analysis saved to /scratch/gilbreth/sramishe/results_QwQ_R1/results_improved/fixed_analysis.csv\n",
      "\n",
      "You can now use these corrected results for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save fixed results to JSON\n",
    "output_data = {\n",
    "    'config': data['config'],\n",
    "    'model_info': data['model_info'],\n",
    "    'directions_stats': data.get('directions_stats', {}),\n",
    "    'baselines': data['baselines'],\n",
    "    'intervention_results_fixed': fixed_results,\n",
    "    'changes_detected': changes_detected,\n",
    "    'old_has_reasoning': old_has_reasoning,\n",
    "    'new_has_reasoning': new_has_reasoning,\n",
    "}\n",
    "\n",
    "output_file = output_path / 'results_fixed.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Fixed results saved to {output_file}\")\n",
    "print(f\"✓ CSV analysis saved to {output_path / 'fixed_analysis.csv'}\")\n",
    "print(f\"\\nYou can now use these corrected results for further analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
