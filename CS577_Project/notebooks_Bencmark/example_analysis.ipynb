{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning Direction Analysis - Example Notebook\n",
    "\n",
    "This notebook demonstrates the basic workflow for analyzing reasoning directions in language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from pipeline_Benchmark.config import get_default_config\n",
    "from pipeline_Benchmark.model_utils import load_model_and_tokenizer, collect_activations, compute_contrastive_directions\n",
    "from pipeline_Benchmark.utils import load_dataset, create_control_dataset, prepare_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_default_config()\n",
    "\n",
    "# For quick testing, use smaller sample sizes\n",
    "config.dataset.gsm8k_sample_size = 10\n",
    "config.dataset.math_sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (this will take a while for large models)\n",
    "print(f\"Loading model: {config.model.rl_model_name}\")\n",
    "\n",
    "model_wrapper = load_model_and_tokenizer(\n",
    "    model_name=config.model.rl_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\"\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model_wrapper.num_layers} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reasoning dataset (GSM8K)\n",
    "gsm8k_data = load_dataset(\n",
    "    config.dataset.gsm8k_path,\n",
    "    split=\"test\",\n",
    "    sample_size=10\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(gsm8k_data)} GSM8K examples\")\n",
    "print(\"\\nExample:\")\n",
    "print(gsm8k_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create control dataset\n",
    "control_data = create_control_dataset(size=10, task_type=\"simple_qa\")\n",
    "\n",
    "print(f\"Created {len(control_data)} control examples\")\n",
    "print(\"\\nExample:\")\n",
    "print(control_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_prompts = prepare_prompts(gsm8k_data, dataset_type=\"gsm8k\", include_cot_prompt=True)\n",
    "control_prompts = prepare_prompts(control_data, dataset_type=\"control\", include_cot_prompt=False)\n",
    "\n",
    "print(\"Reasoning prompt example:\")\n",
    "print(reasoning_prompts[0])\n",
    "print(\"\\nControl prompt example:\")\n",
    "print(control_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations on reasoning tasks\n",
    "print(\"Collecting activations on reasoning tasks...\")\n",
    "reasoning_activations = collect_activations(\n",
    "    model=model_wrapper.model,\n",
    "    tokenizer=model_wrapper.tokenizer,\n",
    "    texts=reasoning_prompts,\n",
    "    batch_size=2,\n",
    "    device=model_wrapper.device\n",
    ")\n",
    "\n",
    "print(f\"Collected activations for {len(reasoning_activations)} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations on control tasks\n",
    "print(\"Collecting activations on control tasks...\")\n",
    "control_activations = collect_activations(\n",
    "    model=model_wrapper.model,\n",
    "    tokenizer=model_wrapper.tokenizer,\n",
    "    texts=control_prompts,\n",
    "    batch_size=2,\n",
    "    device=model_wrapper.device\n",
    ")\n",
    "\n",
    "print(f\"Collected activations for {len(control_activations)} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Reasoning Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute contrastive directions\n",
    "directions = compute_contrastive_directions(\n",
    "    reasoning_activations=reasoning_activations,\n",
    "    control_activations=control_activations,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "print(f\"Computed reasoning directions for {len(directions)} layers\")\n",
    "print(f\"Direction vector shape: {directions[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_Benchmark.model_utils import apply_direction_intervention\n",
    "\n",
    "test_prompt = reasoning_prompts[0]\n",
    "print(f\"Test prompt: {test_prompt}\\n\")\n",
    "\n",
    "# Test different intervention strengths\n",
    "for strength in [-1.0, 0.0, 1.0]:\n",
    "    output = apply_direction_intervention(\n",
    "        model=model_wrapper.model,\n",
    "        tokenizer=model_wrapper.tokenizer,\n",
    "        prompt=test_prompt,\n",
    "        directions=directions,\n",
    "        intervention_strength=strength,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nIntervention strength {strength}:\")\n",
    "    print(output)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot direction magnitudes across layers\n",
    "layers = sorted(directions.keys())\n",
    "magnitudes = [directions[l].norm().item() for l in layers]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(layers, magnitudes, marker='o')\n",
    "plt.xlabel('Layer Index')\n",
    "plt.ylabel('Direction Magnitude')\n",
    "plt.title('Reasoning Direction Magnitude Across Layers')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save directions\n",
    "output_path = \"../results/directions/example_directions.pt\"\n",
    "torch.save(directions, output_path)\n",
    "print(f\"Saved directions to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
